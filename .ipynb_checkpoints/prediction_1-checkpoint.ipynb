{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a4b88f-93a3-4a0a-91ce-b3295768fa31",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff04c64-4996-47f0-90d9-fb21b6e883c7",
   "metadata": {},
   "source": [
    "Importing the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64785200-f579-43c1-9b46-0e4bf91eee74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d91765-a327-4695-b8d6-7b0d67b63b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7be1e0-0f86-4b96-a573-2d1ee2c38449",
   "metadata": {},
   "source": [
    "Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7ba63-774d-4d53-a026-4cab0fa248b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airline_data = pd.read_csv(\"data/test.csv\")\n",
    "airline_data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89583b71-8a4b-4d98-b3c0-6270d8355b5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f04c8-0438-47c0-b793-390bc989e623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['Unnamed: 0', 'id']\n",
    "airline_data = airline_data.drop(columns=columns_to_drop, axis=1)\n",
    "airline_data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479833d-1fed-419d-80f3-b616bf5160cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "I dropped unecessary colomns such as id and numeric-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49772d6-3889-46b1-b4bc-cae95da6f03b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(airline_data.shape)\n",
    "print(airline_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce5ee9-8000-4c98-9ef6-a83b8f43c725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airline_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae1522-2f6a-40ab-9372-091bf6516d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airline_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab0f097-a5c8-4e40-bb73-a66387049929",
   "metadata": {},
   "source": [
    "Over here, I can see that there are some null values for Arrival delay in minutes. Normally we would remove all null rows, but intuition suggests that null might equal to 0 or no delay. So, I performed a data check, but after checking the data, it was found that there are indeed some values where 0 was written. Therefore Null does not necessarily equal 0. Therefore, since kaggle does not have the right data information provided, those rows with null values, needs to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5a825-b1c8-443b-8f09-4a419cdd6600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airline_data = airline_data.dropna(subset=['Arrival Delay in Minutes'])\n",
    "airline_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce5ebe-0843-4d2b-a322-a53d22cc9565",
   "metadata": {},
   "source": [
    "The data is now clean, now I will divide the features and the label, in different data-frames, to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708268cf-4e76-47db-91ef-1eee9bc2063f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airline_features = airline_data.iloc[:,0:22] # Independent variables\n",
    "airline_satisfaction = airline_data['satisfaction'] # Outcome variable\n",
    "airline_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06306cd1-013a-4ba0-a201-317790800845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airline_satisfaction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a966bd7-e7b6-45b4-b180-4b11cfd9e581",
   "metadata": {
    "tags": []
   },
   "source": [
    "The data has been cleaned now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da155b-a054-4838-a671-a2bac3889ea2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589b5dc7-17bb-4689-9af9-2b6e5dd0aa12",
   "metadata": {},
   "source": [
    "The central goal for EDA would be to examine the overall dataset and perform feature reduction and data inspection, to build a clean model. To perform this, I will follow the following steps, in this order to get the best result:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814591e-4aad-4bb7-9208-91149b0faa45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analysis for Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5da5fa-04a3-4628-b64e-84e3c5352bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='satisfaction', data=airline_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e11013-11e9-49ad-bd91-c8741c66ff88",
   "metadata": {},
   "source": [
    "This plot reveals that the final outcome variable of satisfaction is almost equally distributed. Therefore, no new false dummy value creation of sorts is required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4bc3ca-cc00-4e23-83d3-6c1de57741d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb28ac-e0ca-4b37-9c00-a61789f626ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "Goal: I will examine each feature individually to understand its distribution, variability, and potential for feature reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a830d0-18b4-4c5f-8e9b-f893fffddc21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### \"Continuous Numerical Features\" Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ad732-6b01-4b01-935d-7acaf14e2e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set a more visually appealing theme\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "\n",
    "sns.histplot(airline_data['Age'], color='#2ecc71', fill=True, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Age Distribution')\n",
    "axes[0, 0].set_xlabel('Age')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(airline_data['Flight Distance'], color='#3498db', fill=True, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Flight Distance Distribution')\n",
    "axes[0, 1].set_xlabel('Distance (km)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(airline_data['Departure Delay in Minutes'], color='#2ecc71', fill=True, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Departure Delay Distribution')\n",
    "axes[1, 0].set_xlabel('Delay (minutes)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(airline_data['Arrival Delay in Minutes'], color='#3498db', fill=True, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Arrival Delay Distribution')\n",
    "axes[1, 1].set_xlabel('Delay (minutes)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "fig.suptitle('Airline Numeric Data Histograms', fontsize=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74a42e-0ed3-4929-a936-102a0d7313ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Use axes[0] and axes[1] to call scatter on each subplot\n",
    "axes[0].scatter(x=airline_data.index, y=airline_data['Arrival Delay in Minutes'], color='#3498db', alpha=0.6)\n",
    "axes[0].set_title('Arrival Delay Distribution (Plot 1)')\n",
    "axes[0].set_xlabel('Index')\n",
    "axes[0].set_ylabel('Arrival Delay in Minutes')\n",
    "\n",
    "axes[1].scatter(x=airline_data.index, y=airline_data['Departure Delay in Minutes'], color='#3498db', alpha=0.6)\n",
    "axes[1].set_title('Departure Delay Distribution (Plot 2)')\n",
    "axes[1].set_xlabel('Index')\n",
    "axes[1].set_ylabel('Departure Delay in Minutes')\n",
    "\n",
    "# Adjust spacing between the plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bc1c10-f796-4fba-8de9-601c8b392286",
   "metadata": {
    "tags": []
   },
   "source": [
    "### \"Discrete Numerical Features\" Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987bf5e-fce0-491c-a802-c5657bd7ae23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(nrows=7, ncols=2, figsize=(14, 20))\n",
    "plt.subplots_adjust(hspace=0.6, wspace=0.4)\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "# List of attributes to plot and their titles\n",
    "attributes = [\n",
    "    ('Inflight wifi service', 'Inflight Wifi Service'),\n",
    "    ('Departure/Arrival time convenient', 'Departure/Arrival Time Convenient'),\n",
    "    ('Ease of Online booking', 'Ease of Online Booking'),\n",
    "    ('Gate location', 'Gate Location'),\n",
    "    ('Food and drink', 'Food and Drink'),\n",
    "    ('Online boarding', 'Online Boarding'),\n",
    "    ('Seat comfort', 'Seat Comfort'),\n",
    "    ('Inflight entertainment', 'Inflight Entertainment'),\n",
    "    ('On-board service', 'On-board Service'),\n",
    "    ('Leg room service', 'Leg room Service'),\n",
    "    ('Baggage handling', 'Baggage Handling'),\n",
    "    ('Checkin service', 'Check-in Service'),\n",
    "    ('Inflight service', 'Inflight Service'),\n",
    "    ('Cleanliness', 'Cleanliness')\n",
    "]\n",
    "\n",
    "# Loop through each attribute and corresponding axis to plot\n",
    "for i, (attr, title) in enumerate(attributes):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    sns.histplot(airline_data[attr], color=palette[i % len(palette)], fill=True, ax=axes[row][col])\n",
    "    axes[row][col].set_title(title)\n",
    "    axes[row][col].set_xlabel('Rating')\n",
    "    axes[row][col].set_ylabel('Frequency')\n",
    "\n",
    "fig.suptitle('Customer Satisfaction Ratings Across Various Categories', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed84a23-eb8a-442e-bb9b-6838abd5ceab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855364a3-cad7-45a8-8033-fc18364885ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "Goal: This part of the analysis includes looking at the correlation between multiple variables, so that I may remove some, to prevent over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfb773-0b6c-45dc-97c6-363df64acbcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))  # Set the figure size (width, height in inches)\n",
    "\n",
    "sns.heatmap(airline_features.corr(), \n",
    "            cmap=\"YlGnBu\",                # Colormap for vibrant colors\n",
    "            annot=True,                   # Annotate with correlation values\n",
    "            fmt=\".2f\",                    # Format values to 2 decimal places\n",
    "            linewidths=0.5,               # Add space between cells\n",
    "            annot_kws={\"size\": 10},       # Set annotation font size\n",
    "            cbar_kws={\"shrink\": 0.8})     # Shrink color bar for better fit\n",
    "\n",
    "plt.title('Correlation Matrix of Airline Features', fontsize=16, pad=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eaf8a5-9680-441a-8dee-0e4f18a648ea",
   "metadata": {},
   "source": [
    "Based on the analysis, in a sandbox enviornment, these values were looked into and started dropping for feature selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c85611-efc2-4ef3-b7f3-b996b2416dff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sandbox Testing of Each variable with the correlation pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649edb7-b37a-4754-8f4c-21e5f54a10ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Outliers have been removed for visual ease of interpretation, as it was observed that majority of the outliers were clustered for lower values.\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Boxplot for Departure Delay vs Satisfaction without outliers\n",
    "sns.boxplot(x='satisfaction', y='Departure Delay in Minutes', data=airline_data, ax=axes[0], showfliers=False)\n",
    "axes[0].set_title('Departure Delay vs Satisfaction (No Outliers)')\n",
    "axes[0].set_xlabel('Satisfaction')\n",
    "axes[0].set_ylabel('Departure Delay in Minutes')\n",
    "\n",
    "# Calculate statistics for Departure Delay\n",
    "dep_delay_stats = airline_data.groupby('satisfaction')['Departure Delay in Minutes'].describe()\n",
    "\n",
    "# Print statistics to console\n",
    "print(\"Departure Delay Statistics by Satisfaction Level:\")\n",
    "for satisfaction, stats in dep_delay_stats.iterrows():\n",
    "    print(f\"{satisfaction}: Mean: {stats['mean']:.1f}, Median: {stats['50%']:.1f}, Q1: {stats['25%']:.1f}, Q3: {stats['75%']:.1f}\")\n",
    "\n",
    "# Boxplot for Arrival Delay vs Satisfaction without outliers\n",
    "sns.boxplot(x='satisfaction', y='Arrival Delay in Minutes', data=airline_data, ax=axes[1], showfliers=False)\n",
    "axes[1].set_title('Arrival Delay vs Satisfaction (No Outliers)')\n",
    "axes[1].set_xlabel('Satisfaction')\n",
    "axes[1].set_ylabel('Arrival Delay in Minutes')\n",
    "\n",
    "# Calculate statistics for Arrival Delay\n",
    "arr_delay_stats = airline_data.groupby('satisfaction')['Arrival Delay in Minutes'].describe()\n",
    "\n",
    "# Print statistics to console\n",
    "print(\"\\nArrival Delay Statistics by Satisfaction Level:\")\n",
    "for satisfaction, stats in arr_delay_stats.iterrows():\n",
    "    print(f\"{satisfaction}: Mean: {stats['mean']:.1f}, Median: {stats['50%']:.1f}, Q1: {stats['25%']:.1f}, Q3: {stats['75%']:.1f}\")\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7185ce9-84c2-46df-bed4-7e885769e8a6",
   "metadata": {},
   "source": [
    "Analysis: Both of them seem to be of similar distribution and have similar impact on satisfaction. Therefore, either can be chosen. As Arrival delay tends to have slightly lesser outliers, that was chosen for the model. Chosen variable: \"Arrival Delay in Minutes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d9e43-8ec9-4ac6-b8b5-890434b4087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 12))\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Inflight wifi service', data=airline_data, ax=axes[0][0])\n",
    "axes[0][0].set_title('Inflight wifi service')\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Ease of Online booking', data=airline_data, ax=axes[0][1]) \n",
    "axes[0][1].set_title('Ease of Online booking')\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Gate location', data=airline_data, ax=axes[1][0]) \n",
    "axes[1][0].set_title('Gate location')\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Departure/Arrival time convenient', data=airline_data, ax=axes[1][1]) \n",
    "axes[1][1].set_title('Departure/Arrival time convenient')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c1913-3c43-4864-b7fb-9fb479ee18b5",
   "metadata": {},
   "source": [
    "Based on the plots, I could see that \"Ease of online booking\" and \"In flight wifi service\" are better predicters as they have different distribution of values for satisifed vs disatisified. For example for both of them, people who are neutral or disatisfied have voted primarily between 2-3. While people who are satisified have a range form 2-4, and an even greater spread across all values. Therefore both of them were chosen and kept. While the other two were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588bfa3-9510-48a1-b009-5ca30b005416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 12))\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Food and drink', data=airline_data, ax=axes[0])\n",
    "axes[0].set_title('Food and drink')\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Seat comfort', data=airline_data, ax=axes[1]) \n",
    "axes[1].set_title('Seat comfort')\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Inflight entertainment', data=airline_data, ax=axes[2]) \n",
    "axes[2].set_title('Inflight entertainment')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbb8620-5dd3-4006-b812-070af98a4aa5",
   "metadata": {},
   "source": [
    "The first element dropped out of the following is \"food and drink\", as compared to the other two variables, it is not the most strongest predictor, as the distribution for disatisfied and satisfied is similar. The other two were kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c62f9-0b4e-40e0-ba48-7868f0b81bd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 12))\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Food and drink', data=airline_data, ax=axes[0][0])\n",
    "axes[0][0].set_title('Food and drink')\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Cleanliness', data=airline_data, ax=axes[0][1]) \n",
    "axes[0][1].set_title('Cleanliness')\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Seat comfort', data=airline_data, ax=axes[1][0]) \n",
    "axes[1][0].set_title('Seat comfort')\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Inflight entertainment', data=airline_data, ax=axes[1][1]) \n",
    "axes[1][1].set_title('Inflight entertainment')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf5511-1ad0-402e-b8fd-7ec07c298084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 12))\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='On-board service', data=airline_data, ax=axes[0])\n",
    "axes[0].set_title('On-board service')\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Baggage handling', data=airline_data, ax=axes[1]) \n",
    "axes[1].set_title('Baggage handling')\n",
    "\n",
    "sns.boxplot(x='satisfaction', y='Inflight service', data=airline_data, ax=axes[2]) \n",
    "axes[2].set_title('Inflight service')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdefbbe-891e-427b-bc61-bc7b821a994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Departure Delay in Minutes', 'Gate location', 'Departure/Arrival time convenient', 'Food and drink', 'Online boarding', 'Cleanliness', 'Food and drink', 'Seat comfort', 'On-board service', 'Inflight wifi service']\n",
    "airline_data = airline_data.drop(columns=columns_to_drop, axis=1)\n",
    "airline_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb278bdb-8634-4d42-9425-f6d6eeeda242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airline_features = airline_data.iloc[:,0:11] # Independent variables\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.heatmap(airline_features.corr(), \n",
    "            cmap=\"YlGnBu\",                # Colormap for vibrant colors\n",
    "            annot=True,                   # Annotate with correlation values\n",
    "            fmt=\".2f\",                    # Format values to 2 decimal places\n",
    "            linewidths=0.5,               # Add space between cells\n",
    "            annot_kws={\"size\": 10},       # Set annotation font size\n",
    "            cbar_kws={\"shrink\": 0.8})     # Shrink color bar for better fit\n",
    "\n",
    "plt.title('Correlation Matrix of Airline Features', fontsize=16, pad=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb886bf-2127-47b0-ac90-e7251b5f1ebd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Encoding with Catagorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4d670-8b0c-4fef-b568-ff1aaddb2b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_features_enc = pd.get_dummies(airline_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4301331-20e1-4dbc-aae3-30810d11215f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airline_features_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692136ae-d593-4fe1-8feb-1c502474cbb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(airline_features_enc.shape)\n",
    "print(airline_features_enc.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1406df3-636c-479e-8c57-6a0c47999197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airline_features = airline_data.iloc[:,0:11] # Independent variables\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.heatmap(airline_features_enc.corr(), \n",
    "            cmap=\"YlGnBu\",                # Colormap for vibrant colors\n",
    "            annot=True,                   # Annotate with correlation values\n",
    "            fmt=\".2f\",                    # Format values to 2 decimal places\n",
    "            linewidths=0.5,               # Add space between cells\n",
    "            annot_kws={\"size\": 10},       # Set annotation font size\n",
    "            cbar_kws={\"shrink\": 0.8})     # Shrink color bar for better fit\n",
    "\n",
    "plt.title('Correlation Matrix of Airline Features', fontsize=16, pad=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a9217-7f64-421f-88d2-66b896bbe2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "target = airline_data[\"satisfaction\"]\n",
    "print(target.head())\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "target = label_encoder.fit_transform(target)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e73a52-af29-4c38-8a5c-b132ad1fd309",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18835c17-ce7f-4380-b98f-741f4dcc4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "X = airline_features_enc\n",
    "y = airline_data[\"satisfaction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46105345-232c-47f8-8631-fea8d821594f",
   "metadata": {},
   "source": [
    "I have stored the variables in x and y, for easier calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064dc5f9-9138-4d19-8f36-f5670fc0d3c3",
   "metadata": {},
   "source": [
    "I am using a standard scaler to scale the values of X and transforming it, to be used for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b1410-fdd3-420f-a173-a146f0f242ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268deefc-1a02-4706-be04-2adc8cde75bd",
   "metadata": {},
   "source": [
    "I have built the decision tree model and stored it in clf, named variable. The random state allows that each time I run, the output tends to be the same. The class weight allows me to fix the earlier problem, identified during EDA that targer variable count is not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b3f05d-a677-49d5-81be-8f9aa19ef491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "clf = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63cfc1-e54d-4c19-a438-4c619e9c6f96",
   "metadata": {},
   "source": [
    "I will be using grid search, with a cv of 5 to find the optimal values for Decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384535b-fa66-4ad1-af9f-1beaba0287e5",
   "metadata": {},
   "source": [
    "I have now initialised the paramater grid values for the decision tree. ***Max Depth*** ensures how deep the tree would make, starting from None, indicating no limit and testing with low to high level complexity for the tree (5 to 20). By using this, we are making sure that whether a shallow tree is sufficient or more depth is required. Next looking at the ***Min samples split***, has the lowest value of 2, indicating the tree to split a node as long there are at least two samples in it. WHen looking at larger values like 5 or 10, this adds a constraint to split at least 5/10 times, which enforces even more conservative splits. For ***Min Sample Leaf***, when looking at the value of 1 shows that the leaf nodes to have just one sample, which enables the tree to grow without much restricictions. Values 2 and 4, introduce some constratint to the leaf noes must have atleast 2 or 4 samples, respectively. This smooths the model in some cases by preventing it from creating very small, potentially unreliable leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42d78f-531c-4571-8f7b-4164c0b63b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b275fea-d793-4bba-a7b3-e87a20eba796",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb4497-5a65-478a-a813-60179ffb7b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "decision_tree.fit(X_scaled, y)\n",
    "\n",
    "y_pred = decision_tree.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b124f9d-12c4-41cc-b824-5b957e009e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred, pos_label=\"satisfied\")  \n",
    "precision = precision_score(y, y_pred, pos_label=\"satisfied\")\n",
    "recall = recall_score(y, y_pred, pos_label=\"satisfied\")\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred, target_names=['neutral or dissatisfied', 'satisfied']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae6b03-ea5a-44aa-89fe-bf4de86b72eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test) \n",
    "\n",
    "# Predict probabilities for ROC\n",
    "y_prob = decision_tree.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_encoded, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guess')\n",
    "plt.title('ROC Curve for Decision Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a032e-3a68-4e76-9f07-d7ae81db3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(70, 30))\n",
    "plot_tree(\n",
    "    decision_tree, \n",
    "    feature_names=X.columns, \n",
    "    class_names=['No', 'Yes'], \n",
    "    filled=True, \n",
    "    rounded=True, \n",
    "    fontsize=10\n",
    ")\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26411314-e990-4ca4-8bde-687ddd6c99c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4fd80-6f64-4197-977f-39c6122e791b",
   "metadata": {},
   "source": [
    "I have imported the Random Forest Classifier from sklearn's ensemble module, which is a learning method that operates by constructing multiple decision trees during training. I maintained consistency with our previous analysis by using the same 80-20 train-test split and random state of 42. This ensures we can make fair comparisons between our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22f948-db05-46fe-875b-60b24ff67dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "X = airline_features_enc\n",
    "y = airline_data[\"satisfaction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658eb108-18c4-4f0e-9032-fcc8dac88bc5",
   "metadata": {},
   "source": [
    "I have stored the variables in x and y, for easier calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2ed7fb-855c-4d02-9f74-4b64320ce504",
   "metadata": {},
   "source": [
    "I am using a standard scaler to scale the values of X and transforming it, to be used for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302cd671-72d3-4305-a2ac-687ec781789e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e215bf0-1360-4562-b22b-7bea3039f3ef",
   "metadata": {},
   "source": [
    "I have built the decision tree model and stored it in clf, named variable. The random state allows that each time I run, the output tends to be the same. The class weight allows me to fix the earlier problem, identified during EDA that targer variable count is not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1d808-0233-4593-9d89-ea8a9ba70c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efede022-d692-47c4-9db9-fe395e6b6cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(best_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274943bc-06b0-4871-90d5-fcea53d47d26",
   "metadata": {},
   "source": [
    "For the Random Forest model, I implemented a grid search over multiple hyperparameters. The n_estimators parameter tests varying numbers of trees from 10 to 200, allowing us to find the sweet spot between computational efficiency and model robustness. The max_depth values mirror our decision tree analysis, while min_samples_split and min_samples_leaf parameters help control the complexity of individual trees within the forest. By using GridSearchCV with 5-fold cross-validation, it ensures that the parameter selection is robust and generalizable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f37fdb-036d-4129-a7a4-354961e6639d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier with the specified parameters\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators = 200,\n",
    "    max_depth=20,  \n",
    "    min_samples_split = 10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ea200-2f7e-42c2-be23-8e8d02522f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate metrics using y_test and y_pred\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=\"satisfied\")  \n",
    "precision = precision_score(y_test, y_pred, pos_label=\"satisfied\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=\"satisfied\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['neutral or dissatisfied', 'satisfied']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f3e08-79bc-45ca-b402-1d8861e67461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)  # 'neutral or dissatisfied' -> 0, 'satisfied' -> 1\n",
    "\n",
    "# Predict probabilities for ROC\n",
    "y_prob = decision_tree.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_encoded, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guess')\n",
    "plt.title('ROC Curve for Decision Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8baa1-163e-4e2f-9879-ed44f2b77d62",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Bagging Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e4dd10-40d4-44f7-a0a4-5b0a6ca2c11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(airline_features_enc)\n",
    "y = airline_data[\"satisfaction\"]\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Bagging Classifier\n",
    "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959bce5-5a99-4ecd-a023-280d4471fb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0],\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "# Grid search for best parameters\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Bagging Classifier\n",
    "best_bagging = grid_search.best_estimator_\n",
    "print(best_bagging)\n",
    "\n",
    "# Train the best Bagging model\n",
    "best_bagging.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_bagging.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9905db-9644-4178-af3c-38806b3f6513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=\"satisfied\")  \n",
    "precision = precision_score(y_test, y_pred, pos_label=\"satisfied\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=\"satisfied\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['neutral or dissatisfied', 'satisfied']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae018565-2efc-46e6-881b-5426017d6188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)  # 'neutral or dissatisfied' -> 0, 'satisfied' -> 1\n",
    "\n",
    "# Predict probabilities for ROC\n",
    "y_prob = best_bagging.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_encoded, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guess')\n",
    "plt.title('ROC Curve for Bagging Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49429273-20f3-48a0-8237-5b3b720d8d8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Boosting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0961f-cd89-426c-9a8d-de6b85261e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(airline_features_enc)\n",
    "y = airline_data[\"satisfaction\"]\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize AdaBoost Classifier\n",
    "boosting = AdaBoostClassifier(estimator=DecisionTreeClassifier(random_state=42), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20aed1-12d6-47d7-8ae4-2282b9f0c4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid for AdaBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "    'estimator__max_depth': [1, 2, 3, None]\n",
    "}\n",
    "\n",
    "# Grid search for best parameters\n",
    "grid_search = GridSearchCV(estimator=boosting, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best AdaBoost Classifier\n",
    "best_boosting = grid_search.best_estimator_\n",
    "print(best_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864d1a1-ee95-48d4-b7d7-2b2d81fc7918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the best AdaBoost model\n",
    "best_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_boosting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd266b5-2e79-47de-bbeb-91d6de4dfd48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=\"satisfied\")  \n",
    "precision = precision_score(y_test, y_pred, pos_label=\"satisfied\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=\"satisfied\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['neutral or dissatisfied', 'satisfied']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1b629-e265-4738-a69a-96a3fdb935a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)  # 'neutral or dissatisfied' -> 0, 'satisfied' -> 1\n",
    "\n",
    "# Predict probabilities for ROC\n",
    "y_prob = best_boosting.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_encoded, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guess')\n",
    "plt.title('ROC Curve for AdaBoost Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ccec6e-99cf-4c5f-8431-009d8d1fda6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gaussian Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c29fec-31aa-4a98-8979-e653161c54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = airline_features_enc\n",
    "y = airline_data[\"satisfaction\"]\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=23)\n",
    "\n",
    "# Gaussian Naive Bayes classifier\n",
    "GNBclassifier = GaussianNB()\n",
    "\n",
    "# Training with cross-validation on the training set\n",
    "cv_scores = cross_val_score(GNBclassifier, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Fitting the model\n",
    "GNBmodel = GNBclassifier.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "GNBpreds = GNBmodel.predict(X_test)\n",
    "\n",
    "# Calculating precision and recall\n",
    "precision = precision_score(y_test, GNBpreds, pos_label=\"satisfied\")  \n",
    "recall = recall_score(y_test, GNBpreds, pos_label=\"satisfied\") \n",
    "f1 = f1_score(y_test, GNBpreds, pos_label=\"satisfied\")\n",
    "\n",
    "# Printing cross-validation accuracy and test accuracy\n",
    "print(f\"Cross-validation training accuracy (mean): {cv_scores.mean() * 100:.2f}\")\n",
    "print(f\"Training accuracy on full training set: {GNBmodel.score(X_train, y_train) * 100:.2f}\")\n",
    "print(f\"Testing accuracy: {accuracy_score(y_test, GNBpreds) * 100:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"f1: {f1:.2f}\")\n",
    "print(confusion_matrix(y_test, GNBpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15b93a-73e8-401d-8ca5-c8907d4b700a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)  # 'neutral or dissatisfied' -> 0, 'satisfied' -> 1\n",
    "\n",
    "# Predict probabilities for ROC\n",
    "y_prob = GNBmodel.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_encoded, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guess')\n",
    "plt.title('ROC Curve for Gaussian Naive Bayes Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4bec59-5470-4465-8e9a-ad24ef5b41f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Linear Discrimininant Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e695d-c062-4adc-aab9-ac452689e999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = airline_features_enc\n",
    "y = airline_data[\"satisfaction\"]\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=23)\n",
    "\n",
    "# Linear Discriminant Analysis (LDA)\n",
    "LDAmodel = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Cross-validation for LDA on the training set\n",
    "cv_scores_lda = cross_val_score(LDAmodel, X_train, y_train, cv=5)\n",
    "\n",
    "# Fitting the model\n",
    "LDAmodel.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "LDApreds = LDAmodel.predict(X_test)\n",
    "\n",
    "# Printing cross-validation accuracy and test accuracy for LDA\n",
    "print(f\"Cross-validation training accuracy (LDA mean): {cv_scores_lda.mean() * 100:.2f}%\")\n",
    "print(f\"Training accuracy (LDA) on full training set: {LDAmodel.score(X_train, y_train) * 100:.2f}%\")\n",
    "print(f\"Testing accuracy (LDA): {accuracy_score(y_test, LDApreds) * 100:.2f}%\")\n",
    "\n",
    "# Calculating precision, recall, and F1 score\n",
    "precision = precision_score(y_test, LDApreds, pos_label=\"satisfied\")  # Adjust pos_label as needed\n",
    "recall = recall_score(y_test, LDApreds, pos_label=\"satisfied\")        # Adjust pos_label as needed\n",
    "f1 = f1_score(y_test, LDApreds, pos_label=\"satisfied\")                # Adjust pos_label as needed\n",
    "\n",
    "print(f\"Precision (LDA): {precision:.2f}\")\n",
    "print(f\"Recall (LDA): {recall:.2f}\")\n",
    "print(f\"F1 Score (LDA): {f1:.2f}\")\n",
    "\n",
    "# Confusion matrix for LDA\n",
    "print(\"Confusion Matrix (LDA):\")\n",
    "conf_matrix = confusion_matrix(y_test, LDApreds)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064d2a1-831a-434d-957a-b6c5b72066b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)  # 'neutral or dissatisfied' -> 0, 'satisfied' -> 1\n",
    "\n",
    "# Predict probabilities for ROC\n",
    "y_prob = LDAmodel.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_encoded, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guess')\n",
    "plt.title('ROC Curve for Gaussian Naive Bayes Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4d9ba-7c59-4e9a-b8e9-7388965962bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Quadratic Discriminant Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550aebd9-3a69-40ba-ac98-a038d43942da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = airline_features_enc\n",
    "y = airline_data[\"satisfaction\"]\n",
    "\n",
    "\n",
    "# Quadratic Discriminant Analysis (QDA)\n",
    "QDAmodel = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Cross-validation for QDA on the training set\n",
    "cv_scores_qda = cross_val_score(QDAmodel, X_train, y_train, cv=5)\n",
    "\n",
    "# Fitting the model\n",
    "QDAmodel.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "QDApreds = QDAmodel.predict(X_test)\n",
    "\n",
    "\n",
    "# Printing cross-validation accuracy and test accuracy for LDA\n",
    "print(f\"Cross-validation training accuracy (LDA mean): {cv_scores_lda.mean() * 100:.2f}%\")\n",
    "print(f\"Training accuracy (LDA) on full training set: {LDAmodel.score(X_train, y_train) * 100:.2f}%\")\n",
    "print(f\"Testing accuracy (LDA): {accuracy_score(y_test, LDApreds) * 100:.2f}%\")\n",
    "\n",
    "# Calculating precision, recall, and F1 score\n",
    "precision = precision_score(y_test, LDApreds, pos_label=\"satisfied\")  # Adjust pos_label as needed\n",
    "recall = recall_score(y_test, LDApreds, pos_label=\"satisfied\")        # Adjust pos_label as needed\n",
    "f1 = f1_score(y_test, LDApreds, pos_label=\"satisfied\")                # Adjust pos_label as needed\n",
    "\n",
    "print(f\"Precision (LDA): {precision:.2f}\")\n",
    "print(f\"Recall (LDA): {recall:.2f}\")\n",
    "print(f\"F1 Score (LDA): {f1:.2f}\")\n",
    "\n",
    "# Confusion matrix for LDA\n",
    "print(\"Confusion Matrix (LDA):\")\n",
    "conf_matrix = confusion_matrix(y_test, LDApreds)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ce946-aafd-4811-8140-6cf8fbf8beee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)  # 'neutral or dissatisfied' -> 0, 'satisfied' -> 1\n",
    "\n",
    "# Predict probabilities for ROC\n",
    "y_prob = QDAmodel.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_encoded, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guess')\n",
    "plt.title('ROC Curve for Gaussian Naive Bayes Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff063e-ee6d-47ac-959e-a615a6e1cd48",
   "metadata": {
    "tags": []
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af6f58f-088a-4dc8-a96d-b1cb688a7fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "X = airline_features_enc\n",
    "y = airline_data[\"satisfaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dadc90f-553b-4336-a8d9-a682118c158e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859d258-b591-4082-8d6e-11afda3166e6",
   "metadata": {},
   "source": [
    "I imported the KNeighborsClassifier from sklearn and set up the data split to maintain consistency with previous models. This ensures that the KNN model is evaluated on the same training and testing sets, allowing for fair comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c0585f-0115-4e4d-9def-cd636075495d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "nn_list=list(range(1,25))\n",
    "print(nn_list)\n",
    "param_grid = {\n",
    "    'n_neighbors': nn_list,\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'cosine']\n",
    "}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3a177-6543-4e1a-ba1d-5ab3eb25a97a",
   "metadata": {},
   "source": [
    "I initialized the KNN model and defined a parameter grid for hyperparameter tuning. The grid includes a range of `n_neighbors` from 1 to 24, and tests different `weights` ('uniform' and 'distance') and `metrics` ('euclidean', 'manhattan', 'cosine') to find the best configuration. The neighbors parameter is the most important one, as it determines how many nearest neighbors are considered for classification. A higher number of neighbors smooths the decision boundary, while a lower number makes it more complex. Howeever, since the data is linearly separable, the model is not required to have a high number of neighbors. When looking at the weights, the uniform weights are used when all points in each neighborhood are weighted equally, while the distance weights are used when the points are weighted by the inverse of their distance. The metric parameter determines the distance metric used to find nearest neighbors. Euclidian distanace is the most commonly used metric, as it is the most intuitive and straightforward. However, manhattan distance is also a good choice, as it is more robust to outliers and is easier to understand. Cosine distance is used when the data is sparse and the angle between vectors is more important than their magnitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae72bb-9ff2-4364-ab15-9563131ae7fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_knn = grid_search.best_estimator_\n",
    "print(f\"Best KNN Score: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2941bb8-b2b5-447d-a022-6cb0be28c836",
   "metadata": {},
   "source": [
    "Using GridSearchCV, I performed a thorough search over the parameter grid with 5-fold cross-validation. This process identifies the best combination of parameters for the KNN model, ensuring it is well-tuned for the dataset. As expected, the best score was found when using 1 neighbor, uniform weights and euclidean distance, as it is the simplest model and the data is linearly separable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e5083-5463-4fd8-914c-011780f50738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier with the specified parameters\n",
    "knn = KNeighborsClassifier(\n",
    "    metric=\"manhattan\",\n",
    "    n_neighbors=17,\n",
    "    weights=\"distance\",\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16b0a0-d7ad-4795-9ee5-4a4f125a19fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate metrics using y_test and y_pred\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=\"satisfied\")  \n",
    "precision = precision_score(y_test, y_pred, pos_label=\"satisfied\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=\"satisfied\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['neutral or dissatisfied', 'satisfied']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e617e4-17b2-4e19-a225-24633b087738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)  # 'neutral or dissatisfied' -> 0, 'satisfied' -> 1\n",
    "\n",
    "# Predict probabilities for ROC\n",
    "y_prob = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_encoded, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guess')\n",
    "plt.title('ROC Curve for KNN')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff156fe5-385c-48b4-b6e7-93e8970a13e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Clusturing using K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07680cea-eb9e-4dd5-aed0-93f3c735168e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airline_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9137ad-9ae8-433c-b484-820d6652ad16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airline_features_clust = airline_data.drop(\"satisfaction\", axis=1)\n",
    "airline_features_clust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c7116-fa1e-447c-830f-680b9ba12e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming airline_features_clust is your DataFrame\n",
    "categorical_columns = ['Gender', 'Customer Type', 'Type of Travel', 'Class']\n",
    "\n",
    "# Perform dummy encoding\n",
    "airline_data_num = pd.get_dummies(airline_features_clust, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(airline_data_num.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022754e6-84bc-45fb-9a8d-2a8c13268cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(airline_data_num)\n",
    "\n",
    "wcss = []\n",
    "k_values = range(1, 11)\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(scaled_data)\n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf0dfb-1e7f-4f7a-a4bc-30dae9a3a133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, wcss, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('WCSS')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900c99b-8d7c-4e3f-a645-fe876c0bf784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "for k in k_values[1:]:  # Silhouette score is undefined for k=1\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(scaled_data)\n",
    "    score = silhouette_score(scaled_data, cluster_labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Plot Silhouette Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values[1:], silhouette_scores, marker='o', linestyle='--')\n",
    "plt.title('Silhouette Scores')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2a4e7-26ba-407c-888a-bec9bd4169e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimal_k = 4  # Adjust this based on observed results\n",
    "\n",
    "# Final Clustering\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "cluster_labels = kmeans_final.fit_predict(scaled_data)\n",
    "airline_data_num['Cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18502095-6f6e-4131-8a8a-d5dcc3e5d513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'airline_data_num' is your dataframe\n",
    "features = airline_data_num.columns[:-1]\n",
    "\n",
    "# Calculate the number of rows required\n",
    "n_features = len(features)\n",
    "n_cols = 3  # Number of plots per row\n",
    "n_rows = (n_features + n_cols - 1) // n_cols  # Ceiling division to get rows\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6 * n_rows))\n",
    "axes = axes.flatten()  # Flatten to easily iterate through axes\n",
    "\n",
    "# Plot each feature\n",
    "for idx, feature in enumerate(features):\n",
    "    sns.barplot(\n",
    "        data=airline_data_num,\n",
    "        x='Cluster',\n",
    "        y=feature,\n",
    "        ci=None,\n",
    "        estimator=np.mean,\n",
    "        ax=axes[idx]\n",
    "    )\n",
    "    axes[idx].set_title(f'Mean {feature} by Cluster')\n",
    "    axes[idx].set_ylabel(f'Average {feature}')\n",
    "    axes[idx].set_xlabel('Cluster')\n",
    "    axes[idx].grid()\n",
    "\n",
    "# Hide any unused subplots\n",
    "for idx in range(len(features), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a0fda-70d8-4f14-ad34-401273036166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group the data by Cluster and calculate the mean for each feature\n",
    "cluster_means = airline_data_num.groupby('Cluster').mean()\n",
    "\n",
    "# Generate the text-based report\n",
    "for cluster in cluster_means.index:\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    for feature, value in cluster_means.loc[cluster].items():\n",
    "        print(f\"  Feature: {feature}: {value:.2f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c48d8-2c57-44a8-a4e4-9212e94602f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
